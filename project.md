项目概述：书法采集数据可视化

项目目标: 构建一个基于Pyecharts的可交互式书法轨迹与动作数据分析系统。该系统能够读取、解析、对齐并可视化来自不同传感器采集的书写过程数据。

详细目标:
1.  数据读取与解析:
    ◦   能够读取sample目录下的JSON与TXT格式数据文件。

    ◦   解析JSON文件：
        ▪   meta.json: 包含视觉追踪元数据。
        ▪   pen_data.jsonl: 包含毛笔的追踪数据，具体为笔身两个标记点（Marker）的相机坐标系三维空间坐标（x, y, z）及对应采集时间戳（t）。注意需要通过meta.json中的IR相机内参depth_intrinsics把相机坐标系转换到世界坐标系. 世界坐标系由desk_plane定义, 包含0,0点和桌平面的法向量. 最后储存tip_pos_world和tail_pos_world

    ◦   解析TXT文件：
        ▪   包含四个IMU（惯性测量单元）的数据，分别固定在WT1（笔尖）、WT2（手背）、WT3（手腕）、WT4（手肘）。
        ▪   每个数据点包含x, y, z三轴的加速度、角速度、角度等多个维度的数据，以及对应时间戳（t）。

2.  时间戳同步：将来自不同文件（IMU的TXT与毛笔的JSONL）的时间戳进行统一对齐。关键步骤是将IMU数据的时间戳转化为Unix时间戳，以便与pen_data.jsonl中的时间戳基准对齐。 内部使用unix时间戳进行计算. 向用户暴露具体时间(yy-mm-dd-hh:mm:ss)格式.

核心功能:
3.  毛笔轨迹可视化（3D）:
    ◦   数据与图表：基于pen_data.jsonl中的tip_pos_world(相对靠笔尖的marker)和tail_pos_world（笔尾 marker）坐标，生成一张同时呈现笔尖和笔尾的三维空间（x-y-z）轨迹图。
    仅生成time_start和time_end之间的轨迹图. 同时有一个time_forcing参数, 用于高亮选定的时间点.
        ◦   视觉规范：
        ▪   轨迹线颜色：同一张三维轨迹图中，tip_pos_world点使用红色，tail_pos_world使用蓝色
        ▪   时序渐变：两条轨迹线的颜色明度需随时间顺序渐变。选定的时间点颜色较深，原理选定时间点逐渐变浅，以直观呈现书写的时间流向。
        ▪   点间连接：在每个相同的时间戳，用一条细线（如灰色）连接对应的tip_pos_world和tail_pos_world点，以表示毛笔的实时姿态。同时使用一条细线延伸tail_pos_world. 用预设的笔长预测笔尖位置. 通过ui向用户索要预测笔尖位置
        。 桌面接触提示: 预测笔尖是否接触到桌面. 若接触到, 则在轨迹图中的地面用红色点表示.
        。 在每个毛笔轨迹位置, 附上WT1的IMU数据. 取最靠近的两个IMU时间戳的数据做线性插值. 
        

4. 手部动作分析(暂时不实现,仅限规划使用):使用yolo等模型分析视频手部位置(视频暂不在sample中,mp4格式). 然后和WT2,WT3,WT4的IMU数据融合. 在3D空间绘制手部(手背,手腕,手肘) 使用细线连接.
1.  Python 3.x
2.  Pyecharts